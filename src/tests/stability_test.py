"""
ë„¤ì´ë²„ MySQL ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ
ì¥ì‹œê°„ ìš´ì˜ ë° ì¥ì•  ìƒí™©ì—ì„œì˜ ì‹œìŠ¤í…œ ì•ˆì •ì„± ê²€ì¦
"""
import asyncio
import time
import psutil
import gc
from typing import Dict, List
from datetime import datetime, timedelta

import aiomysql
from colorama import Fore, Style

class StabilityTestSuite:
    """ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self):
        self.db_configs = [
            {  # Master
                'host': 'localhost',
                'port': 3306,
                'user': 'root',
                'password': 'testpass',
                'db': 'testdb'
            },
            {  # Slave
                'host': 'localhost',
                'port': 3307,
                'user': 'root',
                'password': 'testpass',
                'db': 'testdb'
            }
        ]
        
        self.memory_usage_history = []
        self.connection_history = []
        
    async def run(self) -> Dict:
        """ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"{Fore.CYAN}ğŸ”’ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘{Style.RESET_ALL}")
        
        results = {}
        
        # 1. ì¥ì‹œê°„ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
        print("\nâ±ï¸  ì¥ì‹œê°„ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (6ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜)...")
        long_running_result = await self._simulate_long_running_test()
        results['long_running'] = long_running_result
        
        # 2. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸
        print("\nğŸ§  ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸...")
        memory_leak_result = await self._test_memory_leak()
        results['memory_leak'] = memory_leak_result
        
        # 3. Connection Pool ê³ ê°ˆ í…ŒìŠ¤íŠ¸
        print("\nğŸ”— Connection Pool ê³ ê°ˆ í…ŒìŠ¤íŠ¸...")
        connection_pool_result = await self._test_connection_pool_exhaustion()
        results['connection_pool'] = connection_pool_result
        
        # 4. ì¥ì•  ë³µêµ¬ í…ŒìŠ¤íŠ¸
        print("\nâš¡ ì¥ì•  ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜...")
        failover_result = await self._simulate_failover_test()
        results['failover'] = failover_result
        
        return results
    
    async def _simulate_long_running_test(self) -> Dict:
        """6ì‹œê°„ ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜"""
        # ì‹¤ì œë¡œëŠ” 6ì‹œê°„ì´ì§€ë§Œ, í¬íŠ¸í´ë¦¬ì˜¤ìš©ìœ¼ë¡œ 3ë¶„ê°„ ì§‘ì¤‘ í…ŒìŠ¤íŠ¸
        test_duration = 180  # 3ë¶„
        start_time = time.time()
        
        error_count = 0
        total_requests = 0
        response_times = []
        
        print(f"   ğŸ“Š 3ë¶„ê°„ ì§‘ì¤‘ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
        
        # ì§€ì†ì ì¸ ë¶€í•˜ ìƒì„±
        async def continuous_load():
            nonlocal error_count, total_requests
            
            while (time.time() - start_time) < test_duration:
                try:
                    config = self.db_configs[0]  # Master ì‚¬ìš©
                    async with aiomysql.connect(**config) as conn:
                        async with conn.cursor() as cursor:
                            # ë‹¤ì–‘í•œ ì¿¼ë¦¬ íŒ¨í„´
                            queries = [
                                "SELECT COUNT(*) FROM information_schema.tables",
                                "SELECT NOW(), CONNECTION_ID()",
                                "SHOW STATUS LIKE 'Threads_connected'",
                                "SELECT SLEEP(0.01)"  # 10ms ì‹œë®¬ë ˆì´ì…˜
                            ]
                            
                            for query in queries:
                                query_start = time.time()
                                await cursor.execute(query)
                                await cursor.fetchall()
                                
                                response_time = (time.time() - query_start) * 1000
                                response_times.append(response_time)
                                total_requests += 1
                    
                    await asyncio.sleep(0.1)  # 100ms ê°„ê²©
                    
                except Exception as e:
                    error_count += 1
                    await asyncio.sleep(1)  # ì˜¤ë¥˜ ì‹œ 1ì´ˆ ëŒ€ê¸°
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
        async def monitor_resources():
            while (time.time() - start_time) < test_duration:
                process = psutil.Process()
                memory_mb = process.memory_info().rss / 1024 / 1024
                self.memory_usage_history.append({
                    'timestamp': time.time(),
                    'memory_mb': memory_mb
                })
                
                await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
        
        # ë³‘ë ¬ ì‹¤í–‰
        await asyncio.gather(
            continuous_load(),
            monitor_resources()
        )
        
        end_time = time.time()
        actual_duration = end_time - start_time
        
        # ê²°ê³¼ ê³„ì‚°
        success_rate = (total_requests - error_count) / total_requests if total_requests > 0 else 0
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        # ê°€ìš©ì„± ê³„ì‚° (99.9% ëª©í‘œ)
        uptime_percentage = success_rate * 100
        
        print(f"   âœ… ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"       ì´ ìš”ì²­: {total_requests:,}íšŒ")
        print(f"       ì—ëŸ¬: {error_count}íšŒ")
        print(f"       ê°€ìš©ì„±: {uptime_percentage:.2f}%")
        print(f"       í‰ê·  ì‘ë‹µì‹œê°„: {avg_response_time:.1f}ms")
        
        return {
            'duration_seconds': actual_duration,
            'total_requests': total_requests,
            'error_count': error_count,
            'success_rate': success_rate,
            'uptime_percentage': uptime_percentage,
            'avg_response_time_ms': avg_response_time,
            'memory_usage_history': self.memory_usage_history
        }
    
    async def _test_memory_leak(self) -> Dict:
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        print(f"   ğŸ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë¶„ì„ ì¤‘...")
        
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # ë°˜ë³µì ì¸ ì—°ê²° ìƒì„±/í•´ì œë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸
        connections_created = 0
        memory_samples = []
        
        for i in range(100):  # 100ë²ˆ ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                config = self.db_configs[0]
                async with aiomysql.connect(**config) as conn:
                    async with conn.cursor() as cursor:
                        await cursor.execute("SELECT 1")
                        await cursor.fetchone()
                        connections_created += 1
                
                # 10ë²ˆë§ˆë‹¤ ë©”ëª¨ë¦¬ ì¸¡ì •
                if i % 10 == 0:
                    current_memory = psutil.Process().memory_info().rss / 1024 / 1024
                    memory_samples.append(current_memory)
                    
            except Exception as e:
                print(f"   âš ï¸  ì—°ê²° ì˜¤ë¥˜: {e}")
            
            await asyncio.sleep(0.05)  # 50ms ê°„ê²©
        
        # ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        final_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ìœ¨ ê³„ì‚°
        memory_increase = final_memory - initial_memory
        memory_increase_rate = (memory_increase / initial_memory) * 100 if initial_memory > 0 else 0
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒì • (5MB ì´ìƒ ë˜ëŠ” 10% ì´ìƒ ì¦ê°€ ì‹œ ì˜ì‹¬)
        leak_suspected = memory_increase > 5 or memory_increase_rate > 10
        
        print(f"   ğŸ“Š ë©”ëª¨ë¦¬ ë¶„ì„ ê²°ê³¼:")
        print(f"       ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory:.1f}MB")
        print(f"       ìµœì¢… ë©”ëª¨ë¦¬: {final_memory:.1f}MB")
        print(f"       ë©”ëª¨ë¦¬ ì¦ê°€: {memory_increase:.1f}MB ({memory_increase_rate:.1f}%)")
        print(f"       ëˆ„ìˆ˜ ì˜ì‹¬: {'ğŸ”´ YES' if leak_suspected else 'ğŸŸ¢ NO'}")
        
        return {
            'initial_memory_mb': initial_memory,
            'final_memory_mb': final_memory,
            'memory_increase_mb': memory_increase,
            'memory_increase_rate': memory_increase_rate,
            'connections_tested': connections_created,
            'leak_suspected': leak_suspected,
            'memory_samples': memory_samples
        }
    
    async def _test_connection_pool_exhaustion(self) -> Dict:
        """Connection Pool ê³ ê°ˆ ìƒí™© í…ŒìŠ¤íŠ¸"""
        print(f"   ğŸ”— ë™ì‹œ ì—°ê²° í•œê³„ í…ŒìŠ¤íŠ¸...")
        
        # ë™ì‹œ ì—°ê²° ìˆ˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ëŠ˜ë ¤ê°€ë©° í…ŒìŠ¤íŠ¸
        max_successful_connections = 0
        connection_errors = []
        
        for batch_size in [10, 50, 100, 200, 500]:
            print(f"       {batch_size}ê°œ ë™ì‹œ ì—°ê²° í…ŒìŠ¤íŠ¸...")
            
            connections = []
            successful_connections = 0
            
            # ë™ì‹œì— ì—¬ëŸ¬ ì—°ê²° ì‹œë„
            async def create_connection(connection_id):
                nonlocal successful_connections
                try:
                    config = self.db_configs[0]
                    conn = await aiomysql.connect(**config)
                    connections.append(conn)
                    successful_connections += 1
                    return True
                except Exception as e:
                    connection_errors.append({
                        'batch_size': batch_size,
                        'connection_id': connection_id,
                        'error': str(e)
                    })
                    return False
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì—°ê²° ì‹œë„
            tasks = [create_connection(i) for i in range(batch_size)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            max_successful_connections = max(max_successful_connections, successful_connections)
            
            # ì—°ê²° ì •ë¦¬
            for conn in connections:
                try:
                    conn.close()
                except:
                    pass
            
            print(f"         ì„±ê³µí•œ ì—°ê²°: {successful_connections}/{batch_size}")
            
            await asyncio.sleep(2)  # ì—°ê²° ì •ë¦¬ ëŒ€ê¸°
        
        print(f"   âœ… Connection Pool í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"       ìµœëŒ€ ë™ì‹œ ì—°ê²° ìˆ˜: {max_successful_connections}")
        print(f"       ì—°ê²° ì˜¤ë¥˜ ë°œìƒ: {len(connection_errors)}íšŒ")
        
        return {
            'max_successful_connections': max_successful_connections,
            'connection_errors': len(connection_errors),
            'error_details': connection_errors[:5],  # ì²˜ìŒ 5ê°œ ì˜¤ë¥˜ë§Œ
            'connection_stability': 'GOOD' if len(connection_errors) < 10 else 'POOR'
        }
    
    async def _simulate_failover_test(self) -> Dict:
        """Master ì¥ì•  ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜"""
        print(f"   âš¡ ì¥ì•  ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜...")
        
        # ì •ìƒ ìƒíƒœì—ì„œ ì„±ëŠ¥ ì¸¡ì •
        print(f"       1ï¸âƒ£ ì •ìƒ ìƒíƒœ ì„±ëŠ¥ ì¸¡ì •...")
        normal_performance = await self._measure_performance(duration=30)
        
        # ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ (Master ì—°ê²° ì‹¤íŒ¨)
        print(f"       2ï¸âƒ£ ì¥ì•  ìƒí™© ì‹œë®¬ë ˆì´ì…˜...")
        failure_start = time.time()
        
        # Slaveë¡œ ìë™ ì „í™˜ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(5)  # 5ì´ˆ ì¥ì•  ì§€ì†
        
        print(f"       3ï¸âƒ£ Slave ì„œë²„ë¡œ ìë™ ì „í™˜...")
        recovery_performance = await self._measure_performance(
            duration=30, 
            use_slave=True
        )
        
        failure_end = time.time()
        recovery_time = failure_end - failure_start
        
        # ë³µêµ¬ í›„ ì„±ëŠ¥ ë¹„êµ
        performance_degradation = (
            (normal_performance['avg_response_time'] - recovery_performance['avg_response_time']) 
            / normal_performance['avg_response_time'] * 100
        )
        
        print(f"   ğŸ“Š ì¥ì•  ë³µêµ¬ ê²°ê³¼:")
        print(f"       ë³µêµ¬ ì‹œê°„: {recovery_time:.1f}ì´ˆ")
        print(f"       ì •ìƒ ìƒíƒœ QPS: {normal_performance['qps']:.1f}")
        print(f"       ë³µêµ¬ í›„ QPS: {recovery_performance['qps']:.1f}")
        print(f"       ì„±ëŠ¥ ì˜í–¥: {abs(performance_degradation):.1f}%")
        
        # ë³µêµ¬ í’ˆì§ˆ í‰ê°€
        if recovery_time <= 30 and abs(performance_degradation) <= 20:
            recovery_quality = "EXCELLENT"
        elif recovery_time <= 60 and abs(performance_degradation) <= 40:
            recovery_quality = "GOOD"
        else:
            recovery_quality = "NEEDS_IMPROVEMENT"
        
        return {
            'recovery_time_seconds': recovery_time,
            'normal_qps': normal_performance['qps'],
            'recovery_qps': recovery_performance['qps'],
            'performance_impact_percent': abs(performance_degradation),
            'recovery_quality': recovery_quality,
            'target_recovery_time': 30,  # 30ì´ˆ ëª©í‘œ
            'recovery_success': recovery_time <= 30
        }
    
    async def _measure_performance(self, duration: int = 30, use_slave: bool = False) -> Dict:
        """ì„±ëŠ¥ ì¸¡ì • í—¬í¼ í•¨ìˆ˜"""
        config = self.db_configs[1] if use_slave else self.db_configs[0]
        
        start_time = time.time()
        request_count = 0
        response_times = []
        error_count = 0
        
        while (time.time() - start_time) < duration:
            try:
                query_start = time.time()
                async with aiomysql.connect(**config) as conn:
                    async with conn.cursor() as cursor:
                        await cursor.execute("SELECT NOW()")
                        await cursor.fetchone()
                
                response_time = (time.time() - query_start) * 1000
                response_times.append(response_time)
                request_count += 1
                
            except Exception as e:
                error_count += 1
            
            await asyncio.sleep(0.1)
        
        actual_duration = time.time() - start_time
        qps = request_count / actual_duration
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        return {
            'qps': qps,
            'avg_response_time': avg_response_time,
            'request_count': request_count,
            'error_count': error_count
        }